{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "w2v_model = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.similarities import Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      question        answer              0               1              2  \\\n",
      "0   enormously  tremendously  appropriately        uniquely   tremendously   \n",
      "1   provisions  stipulations   stipulations  interrelations  jurisdictions   \n",
      "2  haphazardly      randomly    dangerously         densely       randomly   \n",
      "3    prominent   conspicuous       battered         ancient     mysterious   \n",
      "4       zenith      pinnacle     completion        pinnacle         outset   \n",
      "\n",
      "                 3  \n",
      "0        decidedly  \n",
      "1  interpretations  \n",
      "2         linearly  \n",
      "3      conspicuous  \n",
      "4          decline  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 80 entries, 0 to 79\n",
      "Data columns (total 6 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   question  80 non-null     object\n",
      " 1   answer    80 non-null     object\n",
      " 2   0         80 non-null     object\n",
      " 3   1         80 non-null     object\n",
      " 4   2         80 non-null     object\n",
      " 5   3         80 non-null     object\n",
      "dtypes: object(6)\n",
      "memory usage: 3.9+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "synonym_test_dataset = pd.read_csv('A2-DataSet/synonym.csv')\n",
    "\n",
    "print(synonym_test_dataset.head())\n",
    "print(synonym_test_dataset.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_label(question_word, correct_answer, closest_synonym, guess_words):\n",
    "    # Check if question word and at least one guess word are in the vocabulary\n",
    "    if question_word in w2v_model.key_to_index and any(word in w2v_model.key_to_index for word in guess_words):\n",
    "        # Check if the closest guess is correct\n",
    "        if closest_synonym is not None and closest_synonym == correct_answer:\n",
    "            return \"correct\"\n",
    "        else:\n",
    "            return \"wrong\"\n",
    "    else:\n",
    "        return \"guess\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'tranquillity' is not in the vocabulary.\n"
     ]
    }
   ],
   "source": [
    "def closest_synonym(query, list_of_guess_words):\n",
    "    closest_synonym = random.choice(list_of_guess_words) if list_of_guess_words else None\n",
    "    max_similarity = -1\n",
    "\n",
    "    # Check if the query word is in the model's vocabulary\n",
    "    if query not in w2v_model.key_to_index:\n",
    "        print(f\"'{query}' is not in the vocabulary.\")\n",
    "        # Return a random guess word if the query is not in the vocabulary\n",
    "        return closest_synonym\n",
    "\n",
    "    for guess_word in list_of_guess_words:\n",
    "        # Check if the guess word is in the model's vocabulary\n",
    "        if guess_word in w2v_model.key_to_index:\n",
    "            try:\n",
    "                sim_score = w2v_model.similarity(query, guess_word)\n",
    "                if sim_score > max_similarity:\n",
    "                    closest_synonym = guess_word\n",
    "                    max_similarity = sim_score\n",
    "            except KeyError:\n",
    "                # Handle the error if the word is not in the model's vocabulary\n",
    "                continue\n",
    "        else:\n",
    "            print(f\"'{guess_word}' is not in the vocabulary.\")\n",
    "            # Return a random guess word if the query is not in the vocabulary\n",
    "            return closest_synonym\n",
    "\n",
    "    return closest_synonym\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Function to proSV file and apply the closest_synonym function\n",
    "def process_csv(file_path):\n",
    "    \n",
    "    question_words = []\n",
    "    answer_words = []\n",
    "    guess_words = []\n",
    "    labels = []\n",
    "    \n",
    "    \n",
    "    # Read the CSV file into a Pandas DataFrame, skipping the first row\n",
    "    synonym_test_dataset = pd.read_csv(file_path)\n",
    "\n",
    "    # Process each row in the DataFrame\n",
    "    for index, row in synonym_test_dataset.iterrows():\n",
    "        # Split the row into words based on comma\n",
    "        words = row.to_list()\n",
    "        #print(words)\n",
    "\n",
    "        # Store the first word in 'query' and the rest in 'list_of_guess_words'\n",
    "        query = words[0]\n",
    "        #print(query)\n",
    "        answer = words[1]\n",
    "        #print(answer)\n",
    "        list_of_guess_words = words[2:]\n",
    "        #print(list_of_guess_words)\n",
    "\n",
    "        # Call the 'closest_synonym' function and store the result\n",
    "        result = closest_synonym(query, list_of_guess_words)\n",
    "        \n",
    "        question_words.append(query)\n",
    "        answer_words.append(answer)\n",
    "        guess_words.append(result)\n",
    "        labels.append(assign_label(query, answer, result, list_of_guess_words))\n",
    "    \n",
    "    \n",
    "    results_df = pd.DataFrame({'question_word': question_words, 'answer_word': answer_words, 'guess_word': guess_words, 'label': labels})    \n",
    "    results_df.to_csv('word2vec-google-news-300-details.csv', index=False)\n",
    "    \n",
    "    print, results_df\n",
    "\n",
    "file_path = 'A2-DataSet/synonym.csv' \n",
    "processed_results = process_csv(file_path)\n",
    "# processed_results\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
