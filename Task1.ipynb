{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "synonym_test_dataset = pd.read_csv('A2-DataSet/synonym.csv')\n",
    "\n",
    "print(synonym_test_dataset.head())\n",
    "print(synonym_test_dataset.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes up to about 5 minuntes to load\n",
    "w2v_model = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'tranquillity' is not in the vocabulary.\n",
      "   question_word   answer_word    guess_word    label\n",
      "0     enormously  tremendously  tremendously  correct\n",
      "1     provisions  stipulations  stipulations  correct\n",
      "2    haphazardly      randomly      randomly  correct\n",
      "3      prominent   conspicuous   conspicuous  correct\n",
      "4         zenith      pinnacle      pinnacle  correct\n",
      "..           ...           ...           ...      ...\n",
      "75       fashion        manner        manner  correct\n",
      "76      marketed          sold          sold  correct\n",
      "77        bigger        larger        larger  correct\n",
      "78         roots       origins       origins  correct\n",
      "79      normally    ordinarily    ordinarily  correct\n",
      "\n",
      "[80 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "def assign_label(question_word, correct_answer, closest_synonym, guess_words, model):\n",
    "    # Check if question word and at least one guess word are in the vocabulary\n",
    "    if question_word in model.key_to_index and any(word in model.key_to_index for word in guess_words):\n",
    "        # Check if the closest guess is correct\n",
    "        if closest_synonym is not None and closest_synonym == correct_answer:\n",
    "            return \"correct\"\n",
    "        else:\n",
    "            return \"wrong\"\n",
    "    else:\n",
    "        return \"guess\"\n",
    "\n",
    "def closest_synonym(query, list_of_guess_words, model):\n",
    "    closest_synonym = random.choice(list_of_guess_words) if list_of_guess_words else None\n",
    "    max_similarity = -1\n",
    "\n",
    "    # Check if the query word is in the model's vocabulary\n",
    "    if query not in model.key_to_index:\n",
    "        print(f\"'{query}' is not in the vocabulary.\")\n",
    "        # Return a random guess word if the query is not in the vocabulary\n",
    "        return closest_synonym\n",
    "\n",
    "    for guess_word in list_of_guess_words:\n",
    "        # Check if the guess word is in the model's vocabulary\n",
    "        if guess_word in model.key_to_index:\n",
    "            try:\n",
    "                sim_score = model.similarity(query, guess_word)\n",
    "                if sim_score > max_similarity:\n",
    "                    closest_synonym = guess_word\n",
    "                    max_similarity = sim_score\n",
    "            except KeyError:\n",
    "                # Handle the error if the word is not in the model's vocabulary\n",
    "                continue\n",
    "        else:\n",
    "            print(f\"'{guess_word}' is not in the vocabulary.\")\n",
    "            # Return a random guess word if the query is not in the vocabulary\n",
    "            return closest_synonym\n",
    "\n",
    "    return closest_synonym\n",
    "\n",
    "\n",
    "# Function to proSV file and apply the closest_synonym function\n",
    "def process_csv(file_path, model_name, model):\n",
    "    \n",
    "    # Size of the Vocabulary\n",
    "    vocab_size = len(model.key_to_index)\n",
    "\n",
    "    question_words = []\n",
    "    answer_words = []\n",
    "    guess_words = []\n",
    "    labels = []\n",
    "    C = 0\n",
    "    V = 0\n",
    "    \n",
    "    # Read the CSV file into a Pandas DataFrame, skipping the first row\n",
    "    synonym_test_dataset = pd.read_csv(file_path)\n",
    "\n",
    "    # Process each row in the DataFrame\n",
    "    for index, row in synonym_test_dataset.iterrows():\n",
    "        # Split the row into words based on comma\n",
    "        words = row.to_list()\n",
    "        #print(words)\n",
    "\n",
    "        # Store the first word in 'query' and the rest in 'list_of_guess_words'\n",
    "        query = words[0]\n",
    "        #print(query)\n",
    "        answer = words[1]\n",
    "        #print(answer)\n",
    "        list_of_guess_words = words[2:]\n",
    "        #print(list_of_guess_words)\n",
    "\n",
    "        # Call the 'closest_synonym' function and store the result\n",
    "        result = closest_synonym(query, list_of_guess_words, model)\n",
    "        \n",
    "        question_words.append(query)\n",
    "        answer_words.append(answer)\n",
    "        guess_words.append(result)\n",
    "        label = assign_label(query, answer, result, list_of_guess_words, model)\n",
    "        labels.append(label)\n",
    "        \n",
    "        if label == 'correct':\n",
    "            C += 1\n",
    "        if label != 'guess':\n",
    "            V += 1\n",
    "    \n",
    "    if V == 0:\n",
    "        accuracy = 0\n",
    "    else: \n",
    "        accuracy = C/V\n",
    "    \n",
    "    results_df = pd.DataFrame({'question_word': question_words, 'answer_word': answer_words, 'guess_word': guess_words, 'label': labels})    \n",
    "    results_df.to_csv(f\"{model_name}-details.csv\", index=False)\n",
    "    \n",
    "    analysis_df = pd.DataFrame({'model_name': [model_name], 'vocab_size': [vocab_size], 'C': [C], 'V': [V], 'accuracy': accuracy})    \n",
    "    analysis_df.to_csv('analysis.csv', mode='a', index=False, header=not pd.io.common.file_exists('analysis.csv'))\n",
    "    \n",
    "    print(results_df)\n",
    "    \n",
    "file_path = 'A2-DataSet/synonym.csv' \n",
    "processed_results = process_csv(file_path, 'word2vec-google-news-300', w2v_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: we got the corpus names from the offical gensim GitHub page (https://github.com/piskvorky/gensim-data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 376.1/376.1MB downloaded\n"
     ]
    }
   ],
   "source": [
    "# takes about 3 minuntes to load\n",
    "gigaword_model = api.load('glove-wiki-gigaword-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes about 8 minuntes to load\n",
    "fasttext_model = api.load('fasttext-wiki-news-subwords-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes about 5 minuntes to load\n",
    "glove_twitter_200_model = api.load('glove-twitter-200')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes about 2 minuntes to load\n",
    "glove_twitter_25_model = api.load('glove-twitter-25')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'verbosely' is not in the vocabulary.\n",
      "'bipartisanly' is not in the vocabulary.\n",
      "   question_word   answer_word    guess_word    label\n",
      "0     enormously  tremendously  tremendously  correct\n",
      "1     provisions  stipulations  stipulations  correct\n",
      "2    haphazardly      randomly      randomly  correct\n",
      "3      prominent   conspicuous   conspicuous  correct\n",
      "4         zenith      pinnacle      pinnacle  correct\n",
      "..           ...           ...           ...      ...\n",
      "75       fashion        manner        manner  correct\n",
      "76      marketed          sold          sold  correct\n",
      "77        bigger        larger        larger  correct\n",
      "78         roots       origins       origins  correct\n",
      "79      normally    ordinarily    ordinarily  correct\n",
      "\n",
      "[80 rows x 4 columns]\n",
      "'bipartisanly' is not in the vocabulary.\n",
      "   question_word   answer_word    guess_word    label\n",
      "0     enormously  tremendously  tremendously  correct\n",
      "1     provisions  stipulations  stipulations  correct\n",
      "2    haphazardly      randomly      randomly  correct\n",
      "3      prominent   conspicuous   conspicuous  correct\n",
      "4         zenith      pinnacle      pinnacle  correct\n",
      "..           ...           ...           ...      ...\n",
      "75       fashion        manner        manner  correct\n",
      "76      marketed          sold          sold  correct\n",
      "77        bigger        larger        larger  correct\n",
      "78         roots       origins       origins  correct\n",
      "79      normally    ordinarily    ordinarily  correct\n",
      "\n",
      "[80 rows x 4 columns]\n",
      "'interrelations' is not in the vocabulary.\n",
      "'linearly' is not in the vocabulary.\n",
      "'prudently' is not in the vocabulary.\n",
      "'unequaled' is not in the vocabulary.\n",
      "'peculiarly' is not in the vocabulary.\n",
      "'shrewdly' is not in the vocabulary.\n",
      "'verbosely' is not in the vocabulary.\n",
      "'halfheartedly' is not in the vocabulary.\n",
      "'descriptively' is not in the vocabulary.\n",
      "'steadier' is not in the vocabulary.\n",
      "'haltingly' is not in the vocabulary.\n",
      "   question_word   answer_word    guess_word    label\n",
      "0     enormously  tremendously  tremendously  correct\n",
      "1     provisions  stipulations  stipulations  correct\n",
      "2    haphazardly      randomly       densely    wrong\n",
      "3      prominent   conspicuous    mysterious    wrong\n",
      "4         zenith      pinnacle      pinnacle  correct\n",
      "..           ...           ...           ...      ...\n",
      "75       fashion        manner         craze    wrong\n",
      "76      marketed          sold          sold  correct\n",
      "77        bigger        larger        closer    wrong\n",
      "78         roots       origins       origins  correct\n",
      "79      normally    ordinarily  periodically    wrong\n",
      "\n",
      "[80 rows x 4 columns]\n",
      "'interrelations' is not in the vocabulary.\n",
      "'linearly' is not in the vocabulary.\n",
      "'prudently' is not in the vocabulary.\n",
      "'unequaled' is not in the vocabulary.\n",
      "'peculiarly' is not in the vocabulary.\n",
      "'shrewdly' is not in the vocabulary.\n",
      "'verbosely' is not in the vocabulary.\n",
      "'halfheartedly' is not in the vocabulary.\n",
      "'descriptively' is not in the vocabulary.\n",
      "'steadier' is not in the vocabulary.\n",
      "'haltingly' is not in the vocabulary.\n",
      "   question_word   answer_word    guess_word    label\n",
      "0     enormously  tremendously  tremendously  correct\n",
      "1     provisions  stipulations  stipulations  correct\n",
      "2    haphazardly      randomly       densely    wrong\n",
      "3      prominent   conspicuous       ancient    wrong\n",
      "4         zenith      pinnacle      pinnacle  correct\n",
      "..           ...           ...           ...      ...\n",
      "75       fashion        manner        manner  correct\n",
      "76      marketed          sold       diluted    wrong\n",
      "77        bigger        larger        closer    wrong\n",
      "78         roots       origins       origins  correct\n",
      "79      normally    ordinarily  periodically    wrong\n",
      "\n",
      "[80 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "file_path = 'A2-DataSet/synonym.csv' \n",
    "\n",
    "processed_results = process_csv(file_path, 'glove-wiki-gigaword-300', gigaword_model)\n",
    "processed_results = process_csv(file_path, 'fasttext-wiki-news-subwords-300', fasttext_model)\n",
    "processed_results = process_csv(file_path, 'glove-twitter-200', glove_twitter_200_model)\n",
    "processed_results = process_csv(file_path, 'glove-twitter-25', glove_twitter_25_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(self, text):\n",
    "        \"\"\"\n",
    "        Processes the text by tokenizing, removing punctuation and numbers, converting to lowercase, removing stopwords and lemmatizing the words.\n",
    "        Returns a string of processed text (after processing the tokens, they are joined and returned as a single string to late be vectorized).\n",
    "\n",
    "        Args:\n",
    "            text (str): raw text from webpage\n",
    "\n",
    "        Returns:\n",
    "            str: a string of processed text\n",
    "        \"\"\"\n",
    "        # tokenize the text\n",
    "        tokens = word_tokenize(text)\n",
    "        \n",
    "        # remove punctuation and numbers and convert to lowercase\n",
    "        tokens = [word.lower() for word in tokens if word.isalpha()]\n",
    "        \n",
    "        # remove stopwords\n",
    "        tokens = [word for word in tokens if not word in self.stop_words]\n",
    "        \n",
    "        # lemmatize the words\n",
    "        tokens = [self.lemmatizer.lemmatize(word) for word in tokens]\n",
    "            \n",
    "        # join the tokens into a single string with each word separated by a space\n",
    "        tokens_string = ' '.join(tokens)\n",
    "        \n",
    "        # return the processed text\n",
    "        return tokens_string"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
